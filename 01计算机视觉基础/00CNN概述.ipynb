{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4537ced-0a99-4151-a54b-faed141d8777",
   "metadata": {},
   "source": [
    "# CNN概述 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a536237-49c7-45da-be0f-97315f742c68",
   "metadata": {},
   "source": [
    "卷积神经网络（Convolutional Neural Network，简称CNN）是一种深度学习模型，特别适用于处理具有网格结构的数据，如图像。CNN通过模拟人类视觉系统的工作方式来自动并有效地提取数据特征，从而在图像识别、物体检测等任务中取得了卓越的性能。\n",
    "\n",
    "### 主要组成部分\n",
    "\n",
    "1. **输入层**：接收原始数据输入，对于图像数据来说，输入通常是一个二维矩阵（灰度图像）或三维张量（彩色图像，包含RGB三个通道）。\n",
    "\n",
    "2. **卷积层（Convolutional Layer）**：核心部分，使用一组可学习的滤波器（也称为卷积核）滑过输入数据，进行元素乘法和求和操作以生成特征图。每个滤波器都会提取输入数据的一个特定特征，比如边缘、纹理等。通过应用激活函数（如ReLU），可以增加模型的非线性表达能力。\n",
    "\n",
    "3. **池化层（Pooling Layer）**：通常位于卷积层之后，用于减少特征图的空间尺寸，降低计算复杂度和控制过拟合。最常用的池化方法是最大池化（Max Pooling），即从一个局部区域中选取最大值作为输出。\n",
    "\n",
    "4. **全连接层（Fully Connected Layer）**：在经过多个卷积层和池化层后，通常会将特征图展平成一维向量，并通过全连接层将其映射到指定的类别上。全连接层中的每个神经元都与前一层的所有神经元相连。\n",
    "\n",
    "5. **输出层**：根据任务的不同，可能是分类问题的softmax层或者回归问题的线性单元等，用于产生最终的预测结果。\n",
    "\n",
    "### 特点\n",
    "\n",
    "- **参数共享**：卷积核的参数在整个输入数据上共享，减少了模型参数的数量，使得模型更易于训练。\n",
    "- **平移不变性**：由于使用了相同的卷积核，CNN能够识别出不同位置的相同特征。\n",
    "- **层次化特征提取**：深层网络可以从浅层网络学到的基础特征中进一步提取更复杂的特征。\n",
    "\n",
    "CNN已经被广泛应用于计算机视觉领域，包括但不限于图像分类、目标检测、人脸识别、视频分析等，并且在自然语言处理等领域也有应用尝试。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ab44ca-fe05-4b3e-acd6-f699a2bccf54",
   "metadata": {},
   "source": [
    "## 什么是卷积   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d907b16-187a-466a-8a8a-6ced080cc840",
   "metadata": {},
   "source": [
    "卷积是数学中的一个概念，广泛应用于信号处理、图像处理等领域，并且是卷积神经网络（Convolutional Neural Networks, CNN）的核心运算之一。简单来说，卷积是一种通过两个函数\\(f\\)和\\(g\\)生成第三个函数的数学运算，表示为\\(f*g\\)。在CNN中，这两个函数通常是一个输入图像（或特征图）和一个滤波器（也称作卷积核）。\n",
    "\n",
    "### 卷积的基本过程\n",
    "\n",
    "1. **滑动窗口**：将卷积核作为一个滑动窗口，在输入数据（如图像）上逐个位置进行扫描。对于二维图像而言，卷积核会按照从左到右、从上到下的顺序依次覆盖图像的每个子区域。\n",
    "\n",
    "2. **点乘操作**：当卷积核覆盖在一个特定位置时，它与对应的输入数据子区域执行逐元素相乘，然后将结果求和得到一个单一数值。这个过程叫做点乘。\n",
    "\n",
    "3. **输出特征图**：每次点乘操作的结果形成输出特征图的一个元素。随着卷积核在整个输入数据上移动，最终生成整个输出特征图。这个特征图可以看作是输入数据经过滤波器变换后的版本，强调了某些特定类型的特征，比如边缘、纹理等。\n",
    "\n",
    "### 数学表达\n",
    "\n",
    "给定一个大小为\\(n \\times n\\)的输入矩阵\\(I\\)和大小为\\(m \\times m\\)的卷积核\\(K\\)，卷积操作可形式化地定义为：\n",
    "$$ (I * K)(i,j) = \\sum_{u=-\\infty}^{\\infty} \\sum_{v=-\\infty}^{\\infty} I(i+u,j+v)K(u,v) $$\n",
    "\n",
    "实际上，在计算过程中，我们会根据具体的实现对边界进行适当的填充（Padding）和选择步长（Stride），以控制输出尺寸。\n",
    "\n",
    "### 在深度学习中的应用\n",
    "\n",
    "在卷积神经网络中，卷积操作被用来自动地从输入数据中提取有用的特征。通过调整卷积核的权重，CNN能够学习识别出图像中的各种模式，例如边缘、颜色块等基本特征，以及更复杂的结构如物体的部分或整体形状。这使得CNN在图像识别、目标检测等任务中表现出色。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f419e0-ab91-48c5-bb6f-a73752624b52",
   "metadata": {},
   "source": [
    "理解卷积的数学表达确实可能有些挑战性，尤其是初次接触时。让我们简化一下概念，并尝试以更直观的方式解释它。\n",
    "\n",
    "## 简化的卷积概念\n",
    "\n",
    "假设你有一张二维图像（可以想象为一个矩阵，其中每个元素代表一个像素的强度值）和一个小得多的二维数组，我们称之为“滤波器”或“卷积核”。这个滤波器就像是一个放大镜，用来在图像上查找特定的特征，比如边缘或纹理。\n",
    "\n",
    "#### 卷积过程\n",
    "\n",
    "1. **放置滤波器**：首先，将滤波器放在图像的左上角，覆盖一组对应的像素。\n",
    "   \n",
    "2. **逐元素相乘然后求和**：对于滤波器下的每一个像素，将其与滤波器中相应位置的数值相乘，然后把所有的结果加起来得到一个数。这一步骤是整个卷积操作的核心。\n",
    "\n",
    "3. **移动滤波器**：接着，将滤波器向右或向下移动一定的步长（通常是一个像素），重复上述步骤，直到滤波器遍历了整个图像。\n",
    "\n",
    "4. **生成输出**：每执行一次相乘并求和的操作，都会得到一个新的数值。所有这些数值组合在一起形成一个新的矩阵，这就是原始图像经过该滤波器处理后的结果，也称为“特征图”。\n",
    "\n",
    "### 例子\n",
    "\n",
    "假设有如下简化的一维例子来帮助理解：\n",
    "\n",
    "- 输入数据（可以视为一维图像）: [1, 2, 3, 4]\n",
    "- 卷积核: [0.5, -0.5]\n",
    "\n",
    "现在，我们对输入数据应用卷积核：\n",
    "\n",
    "- 步骤1：计算(1*0.5 + 2*-0.5) = -0.5\n",
    "- 步骤2：计算(2*0.5 + 3*-0.5) = -0.5\n",
    "- 步骤3：计算(3*0.5 + 4*-0.5) = -0.5\n",
    "\n",
    "因此，最终的输出是一维数组[-0.5, -0.5, -0.5]。\n",
    "\n",
    "在这个过程中，虽然我们使用了一维的例子进行说明，但同样的原则适用于二维甚至三维的数据，如彩色图像。\n",
    "\n",
    "希望这个更直观的解释能够帮助你更好地理解卷积的概念。如果你有更多问题或者需要进一步的解释，请随时告诉我！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0315d23-79dd-4171-934c-c41248b0e4e6",
   "metadata": {},
   "source": [
    "你说得对，我刚才在写步骤的时候确实表达得不清楚，容易引起误解。让我们重新、**清晰地解释这个过程**。\n",
    "\n",
    "---\n",
    "\n",
    "## 🧮 一维卷积的正确计算示例\n",
    "\n",
    "### 给定：\n",
    "\n",
    "- **输入信号（Input）**：`[1, 2, 3, 4]`\n",
    "- **卷积核（Filter / Kernel）**：`[0.5, -0.5]`\n",
    "\n",
    "我们来一步一步进行**离散一维卷积操作**。\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 步骤说明：\n",
    "\n",
    "1. 把卷积核**翻转**（这是数学定义中的一部分，在CNN中有时会省略这一步，但在传统信号处理中是必要的）：\n",
    "   - 原卷积核是 `[0.5, -0.5]`\n",
    "   - 翻转后变成 `[-0.5, 0.5]`\n",
    "\n",
    "2. 将翻转后的卷积核从左到右滑动通过输入信号，每次与输入的一个局部区域做点乘并求和。\n",
    "\n",
    "---\n",
    "\n",
    "### 🔢 具体计算：\n",
    "\n",
    "#### 第一次滑动（最左）：\n",
    "```\n",
    "输入部分: [1, 2]\n",
    "卷积核:   [-0.5, 0.5]\n",
    "计算:     (1 × -0.5) + (2 × 0.5) = -0.5 + 1.0 = 0.5\n",
    "```\n",
    "\n",
    "#### 第二次滑动：\n",
    "```\n",
    "输入部分: [2, 3]\n",
    "卷积核:   [-0.5, 0.5]\n",
    "计算:     (2 × -0.5) + (3 × 0.5) = -1.0 + 1.5 = 0.5\n",
    "```\n",
    "\n",
    "#### 第三次滑动：\n",
    "```\n",
    "输入部分: [3, 4]\n",
    "卷积核:   [-0.5, 0.5]\n",
    "计算:     (3 × -0.5) + (4 × 0.5) = -1.5 + 2.0 = 0.5\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 输出结果（特征图）：\n",
    "```\n",
    "[0.5, 0.5, 0.5]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ❗你提到的问题在哪？\n",
    "\n",
    "你指出的：\n",
    "```\n",
    "(1*0.5 + 2*-0.5) = -0.5\n",
    "```\n",
    "这种写法本身是对的，但前提是**没有翻转卷积核**。也就是说，如果你不翻转卷积核，直接用原始顺序 `[0.5, -0.5]` 来进行计算，那确实是这样算的。\n",
    "\n",
    "但在标准的数学卷积定义中，是需要翻转卷积核的。而在**卷积神经网络（CNN）中**，通常**并不执行翻转操作**，而是直接做“互相关”（cross-correlation）。\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 总结\n",
    "\n",
    "| 类型 | 是否翻转卷积核 | 名称 |\n",
    "|------|------------------|------|\n",
    "| 数学卷积 | 是 ✅ | 卷积（Convolution） |\n",
    "| CNN 中使用 | 否 ❌ | 互相关（Cross-correlation） |\n",
    "\n",
    "所以在深度学习中，你的理解是正确的，我们不做翻转，直接计算即可。\n",
    "\n",
    "---\n",
    "\n",
    "## 📝 最终结论（CNN中的做法）\n",
    "\n",
    "- 输入：`[1, 2, 3, 4]`\n",
    "- 卷积核：`[0.5, -0.5]`\n",
    "- 不翻转，直接滑动计算：\n",
    "\n",
    "```\n",
    "(1×0.5 + 2×-0.5) = 0.5 - 1.0 = -0.5  \n",
    "(2×0.5 + 3×-0.5) = 1.0 - 1.5 = -0.5  \n",
    "(3×0.5 + 4×-0.5) = 1.5 - 2.0 = -0.5\n",
    "```\n",
    "\n",
    "输出为：\n",
    "```\n",
    "[-0.5, -0.5, -0.5]\n",
    "```\n",
    "\n",
    "这才是你在问题中看到的输出的**正确来源**！\n",
    "\n",
    "---\n",
    "\n",
    "如果你还有任何关于卷积、CNN 或者深度学习的问题，欢迎继续提问 😊"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a816b507-7998-4788-9eff-371f42aeedf9",
   "metadata": {},
   "source": [
    "<a href='https://www.runoob.com/pytorch/pytorch-cnn.html'>菜鸟实例</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16969279-1132-4539-a6bf-bda9ed0aba42",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
