{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6fb03bd-34a4-4af7-9e62-3b7dccac1baf",
   "metadata": {},
   "source": [
    "# 残差网络 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20a721f3-0b34-4c70-921a-be791cee4917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import transforms \n",
    "from torch.utils.data import DataLoader,Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd7c442a-99d1-43a7-8400-f7353684cde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\venvs\\dl\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\venvs\\dl\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97f354fb-f308-4731-b47f-8b024a1b092e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc = nn.Linear(in_features=512,out_features=4) \n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3ba4d3-5504-4669-b046-f6eb31093f56",
   "metadata": {},
   "source": [
    "## 参数冻结与解冻 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "807d4dc3-6f1c-4bde-8df4-1e87bbac061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters(): \n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6268d7c-cd5b-4061-ad29-202863c90dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_Train = transforms.Compose(\n",
    "     [\n",
    "        #数据增强 \n",
    "        transforms.Resize(224),\n",
    "        transforms.RandomCrop(192),\n",
    "        transforms.RandomHorizontalFlip(), #随机水平翻转 \n",
    "        transforms.RandomRotation(degrees=20), #随机旋转  \n",
    "        transforms.ColorJitter(brightness=0.5), #随机扰动\n",
    "        transforms.ColorJitter(contrast=0.5), #增加对比度\n",
    "        # transforms.Resize((192,192)), \n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(mean=[.5,.5,.5],std=[.5,.5,.5]),\n",
    "        \n",
    "        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd5b7e13-00c5-4f7e-8ea2-d74d3505e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_Tst = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((192,192)),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(mean=[.5,.5,.5],std=[.5,.5,.5])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b32e8794-2f5f-49f3-8ae9-a2dab0f0ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_DS = torchvision.datasets.ImageFolder(\n",
    "    '../01计算机视觉基础/4weather/train', \n",
    "    transform = transforms_Train\n",
    ")\n",
    "Tst_DS = torchvision.datasets.ImageFolder(\n",
    "    '../01计算机视觉基础/4weather/test/', \n",
    "    transform=transforms_Tst\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1905d07-67fa-4d37-8c4e-212ff6149456",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_DL = DataLoader(Train_DS,batch_size=32,shuffle=True)\n",
    "Tst_DL = DataLoader(Tst_DS,batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dee4f807-a239-472c-a0fb-595ab33c3ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置优化器 ,因为我们已经冻结了原来的层,这时候只需要关注最后一层就可以了\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(),lr=0.0001) #学习率不要太高,因为已经训练好了\n",
    "#设置损失函数 \n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49fb5ba3-8fe9-42d5-9506-25ba6bf1d348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gpu(Train_DL,TST_DL,Model_m,epoch_,optim,loss_fn): \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0\n",
    "    tstcorrect = 0\n",
    "    tsttotal = 0\n",
    "    tstrunning_loss = 0\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    Model_m.to(device)\n",
    "  \n",
    "    Model_m.train()  # 设置为训练模式,此时dropout层会发挥作用\n",
    "    for x, y in Train_DL:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        y_pred = Model_m(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        # 每个epoch结束后评估模型\n",
    "        # 所有 batch 都训练完后，再计算整个 epoch 的准确率和损失\n",
    "        with torch.no_grad():\n",
    "            y_pred = torch.argmax(y_pred,dim=1)  #沿着类别维度找到最大值的索引位置\n",
    "            correct += (y_pred == y).sum().item() #预测正确的个数\n",
    "            # 因为(y_pred == y).sum()是一个张量,所以为了等式可以数值操作,我们用.item()取值\n",
    "            total += y.size(0) #样本的个数,也就是size返回值的第一个返回值,即行数\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        \n",
    "    epoch_acc = correct/total\n",
    "    epoch_loss = running_loss/len(Train_DL.dataset)\n",
    "\n",
    "    #测试阶段 \n",
    "    Model_m.eval() #转为eval()模式,此时dropout层不会起作用\n",
    "    with torch.no_grad(): #测试不需要反向传播,而是用训练好的模型来测试测试集的数据\n",
    "         for x, y in TST_DL:\n",
    "             x, y = x.to(device), y.to(device)\n",
    "             y_pred =Model_m(x)\n",
    "             loss = loss_fn(y_pred, y)\n",
    "             \n",
    "             y_pred = torch.argmax(y_pred,dim=1)   #获取真正的预测结果,不懂就往上巴拉argmax\n",
    "             tstcorrect += (y_pred == y).sum().item() #预测正确的个数\n",
    "             tsttotal += y.size(0) #样本的个数\n",
    "             tstrunning_loss += loss.item()\n",
    "             \n",
    "    tstepoch_acc = tstcorrect/tsttotal\n",
    "    tstepoch_loss = tstrunning_loss/len(TST_DL.dataset)\n",
    "\n",
    "    print(\n",
    "        f'epoch:{epoch} | loss:{epoch_loss:.3f} | acc:{epoch_acc:.3f} | tstloss:{tstepoch_loss:.3f} | tstacc:{tstepoch_acc:.3f}'\n",
    "    )\n",
    "\n",
    "    return epoch_loss,epoch_acc,tstepoch_loss,tstepoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5291364-7e6d-40d7-b4b6-25ab9c66a8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': [Parameter containing:\n",
       "   tensor([[-6.7192e-03, -1.4244e-02,  2.4399e-02,  ..., -3.3374e-02,\n",
       "            -1.4130e-02,  2.7595e-02],\n",
       "           [-2.7468e-02,  9.3642e-03,  5.9742e-03,  ..., -9.5583e-03,\n",
       "             3.4777e-02, -2.8015e-02],\n",
       "           [ 2.3504e-02,  1.4099e-02,  1.2068e-02,  ...,  2.8718e-03,\n",
       "             1.3207e-02,  2.0251e-04],\n",
       "           [ 3.1553e-02,  4.3489e-05,  1.7658e-02,  ...,  9.2012e-03,\n",
       "             2.6336e-02,  1.2223e-02]], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.0073, -0.0101,  0.0325, -0.0055], requires_grad=True)],\n",
       "  'lr': 0.0001,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'eps': 1e-08,\n",
       "  'weight_decay': 0,\n",
       "  'amsgrad': False,\n",
       "  'maximize': False,\n",
       "  'foreach': None,\n",
       "  'capturable': False,\n",
       "  'differentiable': False,\n",
       "  'fused': None,\n",
       "  'decoupled_weight_decay': False}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b62f2ec6-65ae-4c79-a2be-9be53e9a11df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 | loss:0.048 | acc:0.258 | tstloss:0.024 | tstacc:0.351\n",
      "Epoch 1: 学习率已更新为 1.00e-04\n",
      "epoch:1 | loss:0.044 | acc:0.313 | tstloss:0.022 | tstacc:0.453\n",
      "Epoch 2: 学习率已更新为 1.00e-04\n",
      "epoch:2 | loss:0.041 | acc:0.390 | tstloss:0.021 | tstacc:0.489\n",
      "Epoch 3: 学习率已更新为 1.00e-04\n",
      "epoch:3 | loss:0.038 | acc:0.516 | tstloss:0.020 | tstacc:0.538\n",
      "Epoch 4: 学习率已更新为 1.00e-04\n",
      "epoch:4 | loss:0.035 | acc:0.564 | tstloss:0.018 | tstacc:0.613\n",
      "Epoch 5: 学习率已更新为 9.00e-05\n",
      "epoch:5 | loss:0.034 | acc:0.613 | tstloss:0.018 | tstacc:0.596\n",
      "Epoch 6: 学习率已更新为 9.00e-05\n",
      "epoch:6 | loss:0.032 | acc:0.698 | tstloss:0.017 | tstacc:0.640\n",
      "Epoch 7: 学习率已更新为 9.00e-05\n",
      "epoch:7 | loss:0.031 | acc:0.691 | tstloss:0.016 | tstacc:0.680\n",
      "Epoch 8: 学习率已更新为 9.00e-05\n",
      "epoch:8 | loss:0.029 | acc:0.769 | tstloss:0.015 | tstacc:0.711\n",
      "Epoch 9: 学习率已更新为 9.00e-05\n",
      "epoch:9 | loss:0.029 | acc:0.748 | tstloss:0.015 | tstacc:0.711\n",
      "Epoch 10: 学习率已更新为 8.10e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "scheduler = StepLR(optimizer=optimizer, step_size=5, gamma=0.9) #设置指定的优化器衰减策略,每5个epoch衰减一次,指定每次的被乘因子为0.9\n",
    "train_loss_gpu = []\n",
    "train_acc_gpu = []\n",
    "tst_loss_gpu = []\n",
    "tst_acc_gpu = []\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "      # 每个 epoch 都训练\n",
    "    epoch_loss, epoch_acc, tstepoch_loss, tstepoch_acc = fit_gpu(\n",
    "        Train_DL=Train_DL,\n",
    "        TST_DL=Tst_DL,\n",
    "        Model_m=model,\n",
    "        epoch_=epoch,\n",
    "        optim=optimizer,\n",
    "        loss_fn=loss_fn\n",
    "    )\n",
    "    \n",
    "    # 记录指标\n",
    "    train_loss_gpu.append(epoch_loss)\n",
    "    train_acc_gpu.append(epoch_acc)\n",
    "    tst_loss_gpu.append(tstepoch_loss)\n",
    "    tst_acc_gpu.append(tstepoch_acc)\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {epoch+1}: 学习率已更新为 {current_lr:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee1249-73a7-4837-90d8-6ec0091fbd80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
