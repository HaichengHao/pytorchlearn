{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98197f17-dd60-4662-95fe-7e943c9b68f7",
   "metadata": {},
   "source": [
    "`.argmax()` 是 PyTorch 中的一个非常常用的函数，**它的作用是返回张量中某个维度上最大值的索引（位置）**。\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 通俗理解：\n",
    "\n",
    "你可以把它想象成在一堆数字中找出“哪个位置上的数最大”。\n",
    "\n",
    "---\n",
    "\n",
    "## 🔧 基本语法：\n",
    "\n",
    "```python\n",
    "torch.argmax(input, dim=None, keepdim=False)\n",
    "```\n",
    "\n",
    "- `input`: 输入的张量（Tensor）\n",
    "- `dim`: 指定沿着哪个维度找最大值的位置\n",
    "- `keepdim`: 是否保持原来的维度结构（一般训练时不关心这个）\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 示例讲解\n",
    "\n",
    "假设你有一个输出张量表示模型对每个类别的预测分数（logits），比如一个 batch 有 3 个样本，每个样本有 5 个类别：\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "logits = torch.tensor([\n",
    "    [2.0, 1.0, 0.1, 0.5, 0.0],   # 第一个样本的最大值是 2.0，在第0位\n",
    "    [0.5, 3.0, 1.2, 0.1, 0.2],   # 第二个样本的最大值是 3.0，在第1位\n",
    "    [0.1, 0.2, 0.6, 2.0, 0.1]    # 第三个样本的最大值是 2.0，在第3位\n",
    "])\n",
    "\n",
    "preds = torch.argmax(logits, dim=1) #注意这里指定的是按照维度1,也就是按照每一行来判断,如果是0则按列来\n",
    "print(preds)\n",
    "```\n",
    "\n",
    "### 输出：\n",
    "```\n",
    "tensor([0, 1, 3])\n",
    "```\n",
    "\n",
    "这说明：\n",
    "- 第一个样本被预测为类别 0\n",
    "- 第二个样本被预测为类别 1\n",
    "- 第三个样本被预测为类别 3\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 在分类任务中怎么用？\n",
    "\n",
    "在图像分类、文本分类等任务中，神经网络的最后一层输出通常是不经过 softmax 的原始得分（logits），然后使用 `.argmax()` 来找到预测的类别。\n",
    "\n",
    "### 示例：手写数字识别（MNIST）\n",
    "\n",
    "```python\n",
    "outputs = model(images)              # outputs.shape = (batch_size, 10)\n",
    "predicted_labels = torch.argmax(outputs, dim=1)  # 找出每一行中最大值的索引\n",
    "```\n",
    "\n",
    "这样你就得到了模型对每个图片的预测类别（0~9）。\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ 注意事项\n",
    "\n",
    "- `dim=1` 表示按行找最大值的索引（即每个样本选一个最可能的类别）\n",
    "- `dim=0` 表示按列找最大值的索引（通常用于比较不同样本的同一类别）\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 和 `softmax` 的区别\n",
    "\n",
    "| 方法 | 描述 | 是否可导 | 是否返回概率 |\n",
    "|------|------|-----------|---------------|\n",
    "| `argmax` | 返回最大值的索引（类别编号） | ❌ 不可导（不能用于反向传播） | ❌ 否 |\n",
    "| `softmax` | 将输出转换为概率分布 | ✅ 可导 | ✅ 是 |\n",
    "\n",
    "> 在训练时我们不需要 `argmax`，因为损失函数如 `CrossEntropyLoss` 已经处理了 logits。  \n",
    "> **只有在评估或推理阶段才使用 `argmax` 来获取最终预测结果。**\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 总结一句话：\n",
    "\n",
    "> `.argmax()` 的作用是从模型输出中找出预测概率最大的那个类别编号，常用于分类任务中获取最终预测结果。\n",
    "\n",
    "如果你正在做图像分类、文本分类、或者手写数字识别，这个函数是你最后一步获取预测标签的好帮手 😊\n",
    "\n",
    "需要我帮你写一个完整的预测流程代码吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae3827b-f832-4a73-8546-573afdfe3520",
   "metadata": {},
   "source": [
    "\n",
    "获取类别得分有什么用呢\n",
    "非常好的问题！我们来深入聊聊：\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 **为什么我们要用 `torch.argmax(y_pred, dim=1)` 获取类别得分对应的类别编号？**\n",
    "\n",
    "### ✅ 一句话总结：\n",
    "> 我们获取类别得分的目的是为了**从模型输出中找出预测概率最高的类别标签（class label）**，从而判断模型对当前样本的预测结果。\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 分类任务的本质\n",
    "\n",
    "在分类任务中，比如图像识别、文本分类等，我们的目标是让模型回答这样一个问题：\n",
    "\n",
    "> “这个输入属于哪一类？”\n",
    "\n",
    "模型的输出通常是一个向量，表示每个类别的“得分”或“概率”，例如：\n",
    "\n",
    "```\n",
    "[2.0, -1.0, 0.5] → 表示三个类别的得分\n",
    "```\n",
    "\n",
    "这三个数字分别代表该样本属于类别 0、类别 1 和类别 2 的“置信度”。\n",
    "\n",
    "我们使用 `argmax` 来选出得分最高的那个类别编号，作为最终的预测结果：\n",
    "\n",
    "```python\n",
    "predicted_class = torch.argmax([2.0, -1.0, 0.5], dim=0)\n",
    "# predicted_class = 0\n",
    "```\n",
    "\n",
    "这样我们就能知道模型认为这个样本最可能是哪一个类别了。\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 举个实际例子：猫狗鸟分类\n",
    "\n",
    "假设你训练了一个模型来识别图片中的动物，有三类：\n",
    "\n",
    "- 类别 0：猫\n",
    "- 类别 1：狗\n",
    "- 类别 2：鸟\n",
    "\n",
    "模型输出为：\n",
    "\n",
    "```python\n",
    "y_pred = [1.2, 3.4, 0.5]\n",
    "```\n",
    "\n",
    "这表示：\n",
    "\n",
    "| 类别 | 得分 |\n",
    "|------|------|\n",
    "| 猫   | 1.2  |\n",
    "| 狗   | 3.4  |\n",
    "| 鸟   | 0.5  |\n",
    "\n",
    "使用 `torch.argmax(y_pred, dim=0)`（如果是单个样本）或 `dim=1`（如果是 batch）后得到：\n",
    "\n",
    "```python\n",
    "predicted_class = 1  # 模型预测是“狗”\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 这些类别得分还能用来做什么？\n",
    "\n",
    "除了用于预测类别之外，类别得分还有很多用途：\n",
    "\n",
    "### 1. **计算准确率（Accuracy）**\n",
    "- 对比预测类别和真实标签是否一致。\n",
    "- 用于评估模型性能。\n",
    "\n",
    "```python\n",
    "correct += (predicted_class == true_label).sum().item()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **计算损失（Loss）**\n",
    "- 使用 `nn.CrossEntropyLoss()` 直接传入原始得分（logits）和真实标签即可。\n",
    "- 不需要 softmax 或 argmax！\n",
    "\n",
    "```python\n",
    "loss = criterion(y_pred, y_true)  # y_pred 是 logits\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **可视化模型信心（Confidence）**\n",
    "- 可以用 `softmax` 把得分转换成概率，表示模型有多确定自己的预测。\n",
    "\n",
    "```python\n",
    "probs = F.softmax(y_pred, dim=1)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **多标签分类或 Top-k 预测**\n",
    "- 如果你想知道模型认为前 2 个最可能的类别，可以用 `topk()`：\n",
    "\n",
    "```python\n",
    "values, indices = torch.topk(y_pred, k=2, dim=1)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📈 总结表格：类别得分的作用\n",
    "\n",
    "| 功能 | 是否需要类别得分 | 是否需要 argmax |\n",
    "|------|------------------|------------------|\n",
    "| 预测类别 | ✅ 是 | ✅ 是 |\n",
    "| 计算 loss | ✅ 是（直接输入 logits） | ❌ 否 |\n",
    "| 转换为概率 | ✅ 是 | ❌ 否 |\n",
    "| Top-k 预测 | ✅ 是 | ✅ 是（或 topk） |\n",
    "| 可视化信心 | ✅ 是 | ❌ 否 |\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 总结一句话：\n",
    "\n",
    "> **获取类别得分并使用 argmax 找出最大值索引，是为了将模型输出的数值转化为人类可理解的“这个样本属于哪一类”的预测结果。这是分类任务中最关键的一步。**\n",
    "\n",
    "如果你是在写图像分类、文本分类、语音识别等项目，这一步几乎是必做的操作 😊\n",
    "\n",
    "如果你想了解 `softmax` 和 `argmax` 的区别，或者想看看如何把得分变成概率，也欢迎继续提问！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4699ff-de95-4146-9041-c9354d9ce64b",
   "metadata": {},
   "source": [
    "在 PyTorch 中，`dim` 参数用于指定张量操作的方向。理解 `dim=0` 和 `dim=1` 的区别及其适用场景对于正确使用 PyTorch 进行深度学习任务至关重要。下面详细解释这两个维度的区别以及它们适用的不同场景。\n",
    "\n",
    "### 🔢 维度的基本概念\n",
    "\n",
    "假设我们有一个形状为 `(batch_size, num_classes)` 的二维张量：\n",
    "\n",
    "```python\n",
    "y_pred = torch.tensor([\n",
    "    [2.0, 1.0, 0.1],   # 第一个样本对3个类别的预测得分\n",
    "    [0.5, 2.0, 1.0],   # 第二个样本...\n",
    "    [0.1, 0.2, 3.0],   # 第三个样本...\n",
    "    [1.0, 0.5, 0.2]    # 第四个样本...\n",
    "])\n",
    "```\n",
    "\n",
    "这里，`dim=0` 指的是第一个维度（即 batch 维度），而 `dim=1` 指的是第二个维度（即类别维度）。\n",
    "\n",
    "---\n",
    "\n",
    "## 📝 `dim=0` 场景\n",
    "\n",
    "### ✅ **沿着 batch 维度进行操作**\n",
    "\n",
    "#### 1. **寻找每个类别中最大值的索引**\n",
    "- 如果你想知道在整个 batch 中，哪个样本对某个类别的得分最高，可以使用 `argmax(dim=0)`。\n",
    "\n",
    "```python\n",
    "torch.argmax(y_pred, dim=0)\n",
    "# 输出：tensor([0, 1, 2]) 表示第0个样本对类别0得分最高，第1个样本对类别1得分最高，第2个样本对类别2得分最高。\n",
    "```\n",
    "\n",
    "#### 2. **计算整个 batch 的统计量**\n",
    "- 计算所有样本在某一类别上的总和、平均值等。\n",
    "\n",
    "```python\n",
    "torch.sum(y_pred, dim=0)  # 每个类别的总得分\n",
    "torch.mean(y_pred, dim=0) # 每个类别的平均得分\n",
    "```\n",
    "\n",
    "#### 3. **跨样本比较**\n",
    "- 比较不同样本在同一类别上的表现。\n",
    "\n",
    "---\n",
    "\n",
    "## 📝 `dim=1` 场景\n",
    "\n",
    "### ✅ **沿着类别维度进行操作**\n",
    "\n",
    "#### 1. **获取每个样本的预测类别**\n",
    "- 在分类任务中，你通常需要找出每个样本最可能属于的类别。这时你会用到 `argmax(dim=1)`。\n",
    "\n",
    "```python\n",
    "torch.argmax(y_pred, dim=1)\n",
    "# 输出：tensor([0, 1, 2, 0]) 表示第一个样本预测为类别0，第二个样本预测为类别1，以此类推。\n",
    "```\n",
    "\n",
    "#### 2. **计算每个样本的统计量**\n",
    "- 对于每个样本，你可以计算其对各个类别的总和、平均值等。\n",
    "\n",
    "```python\n",
    "torch.sum(y_pred, dim=1)  # 每个样本的总得分\n",
    "torch.mean(y_pred, dim=1) # 每个样本的平均得分\n",
    "```\n",
    "\n",
    "#### 3. **应用 softmax 或其他激活函数**\n",
    "- 在分类任务中，将模型输出的 logits 转换为概率分布时，通常是对类别维度应用 softmax。\n",
    "\n",
    "```python\n",
    "F.softmax(y_pred, dim=1)\n",
    "```\n",
    "\n",
    "#### 4. **跨类别比较**\n",
    "- 比较同一个样本在不同类别上的得分情况。\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 实际应用场景对比\n",
    "\n",
    "| 场景 | 使用 `dim=0` | 使用 `dim=1` |\n",
    "|------|--------------|--------------|\n",
    "| 获取每个样本的预测类别 | ❌ 不适合 | ✅ 是 |\n",
    "| 获取每个类别中的最佳样本 | ✅ 是 | ❌ 不适合 |\n",
    "| 计算每个类别的总得分或平均得分 | ✅ 是 | ❌ 不适合 |\n",
    "| 计算每个样本的总得分或平均得分 | ❌ 不适合 | ✅ 是 |\n",
    "| 应用 softmax | ❌ 不适合 | ✅ 是 |\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 示例代码\n",
    "\n",
    "### 使用 `dim=0`：\n",
    "```python\n",
    "import torch\n",
    "\n",
    "y_pred = torch.tensor([\n",
    "    [2.0, 1.0, 0.1],\n",
    "    [0.5, 2.0, 1.0],\n",
    "    [0.1, 0.2, 3.0],\n",
    "    [1.0, 0.5, 0.2]\n",
    "])\n",
    "\n",
    "# 找出每个类别中得分最高的样本索引\n",
    "best_sample_per_class = torch.argmax(y_pred, dim=0)\n",
    "print(best_sample_per_class)  # tensor([0, 1, 2])\n",
    "\n",
    "# 计算每个类别的总得分\n",
    "sum_per_class = torch.sum(y_pred, dim=0)\n",
    "print(sum_per_class)  # tensor([3.6, 3.7, 4.3])\n",
    "```\n",
    "\n",
    "### 使用 `dim=1`：\n",
    "```python\n",
    "# 获取每个样本的预测类别\n",
    "predicted_classes = torch.argmax(y_pred, dim=1)\n",
    "print(predicted_classes)  # tensor([0, 1, 2, 0])\n",
    "\n",
    "# 计算每个样本的总得分\n",
    "sum_per_sample = torch.sum(y_pred, dim=1)\n",
    "print(sum_per_sample)  # tensor([3.1, 3.5, 3.3, 1.7])\n",
    "\n",
    "# 应用 softmax\n",
    "probabilities = F.softmax(y_pred, dim=1)\n",
    "print(probabilities)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 总结一句话：\n",
    "\n",
    "> - **`dim=0`** 适用于你需要跨样本进行操作（如找到每个类别下的最佳样本，或者计算每个类别的统计数据）。\n",
    "> - **`dim=1`** 则适用于你需要对每个样本内部的操作（如找到每个样本的最佳类别预测，或者计算每个样本的统计数据）。\n",
    "\n",
    "希望这些解释能帮助你更好地理解 `dim` 参数的使用！如果你有更多问题或需要进一步的例子，请随时提问 😊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8eb6db-6824-487a-a78d-8984c659b512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
