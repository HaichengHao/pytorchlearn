{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab3f0dc1-ef19-4f69-89f6-e667099cdb02",
   "metadata": {},
   "source": [
    "ResNet（Residual Network）是深度学习领域具有里程碑意义的卷积神经网络（CNN），其核心创新在于**残差结构（Residual Block）**，该结构有效解决了深层网络训练中的梯度消失/爆炸问题，使得训练超深层网络（如1000层以上）成为可能。以下从残差结构和ResNet整体两方面详细介绍：\n",
    "\n",
    "\n",
    "### 一、残差结构（Residual Block）\n",
    "残差结构是ResNet的核心组件，其设计初衷是解决“深层网络性能退化”问题——当网络深度增加到一定程度后，模型精度会先提升再饱和，最终甚至下降（并非过拟合，而是优化困难）。\n",
    "\n",
    "\n",
    "#### 1. 核心思想：学习残差而非直接映射\n",
    "传统深层网络中，每一层试图学习输入到输出的“直接映射”（记为$H(x)$）；而残差结构则通过**跳跃连接（Skip Connection）**，将输入$x$直接传到输出，转而学习“残差函数”$F(x) = H(x) - x$。此时，网络的实际输出为：  \n",
    "$$H(x) = F(x) + x$$  \n",
    "\n",
    "- 若$H(x)$是理想的映射，残差$F(x)$可能更接近0，网络更容易学习（只需拟合小扰动）；  \n",
    "- 梯度反向传播时，残差$F(x)$的梯度可直接通过跳跃连接传递到浅层，避免梯度消失。  \n",
    "\n",
    "\n",
    "#### 2. 两种典型残差块结构\n",
    "根据网络深度不同，残差块分为两种类型：\n",
    "\n",
    "\n",
    "##### （1）基本块（Basic Block）\n",
    "用于较浅的ResNet（如ResNet-18、34），结构简单，由**2个3x3卷积层**堆叠而成，配合批量归一化（BN）和ReLU激活函数。  \n",
    "- 流程：输入$x$ → 卷积层1（3x3，BN+ReLU） → 卷积层2（3x3，BN） → 与跳跃连接的$x$相加 → ReLU输出。  \n",
    "- 示意图简化：  \n",
    "  $$x \\rightarrow [Conv3x3 \\rightarrow BN \\rightarrow ReLU \\rightarrow Conv3x3 \\rightarrow BN] + x \\rightarrow ReLU$$  \n",
    "\n",
    "\n",
    "##### （2）瓶颈块（Bottleneck Block）\n",
    "用于较深的ResNet（如ResNet-50、101、152），通过1x1卷积减少计算量（“瓶颈”得名于中间层通道数更少）。结构为**1x1卷积 → 3x3卷积 → 1x1卷积**，同样配合BN和ReLU。  \n",
    "- 作用：1x1卷积先将输入通道数“降维”（减少计算），3x3卷积提取特征，最后1x1卷积“升维”恢复通道数。  \n",
    "- 流程：输入$x$ → 1x1卷积（降维，BN+ReLU） → 3x3卷积（特征提取，BN+ReLU） → 1x1卷积（升维，BN） → 与跳跃连接的$x$相加 → ReLU输出。  \n",
    "\n",
    "\n",
    "#### 3. 跳跃连接（Skip Connection）的细节\n",
    "跳跃连接是残差结构的关键，其作用是将输入$x$“短路”到输出，实现$F(x) + x$的操作。根据输入$x$与主路径输出的维度是否一致，跳跃连接分为两种：  \n",
    "- **恒等捷径（Identity Shortcut）**：当主路径输出与$x$的通道数、空间尺寸（高/宽）相同时，直接将$x$与主路径输出相加（无需额外操作）。  \n",
    "- **投影捷径（Projection Shortcut）**：当主路径因降采样（步长=2）或通道数变化导致维度不一致时，通过1x1卷积对$x$进行“维度调整”（匹配主路径输出的通道数和尺寸），再相加。  \n",
    "\n",
    "\n",
    "### 二、ResNet整体结构\n",
    "ResNet通过堆叠上述残差块构建深层网络，其核心是“以残差块为单元”，逐步提升网络深度和特征提取能力。\n",
    "\n",
    "\n",
    "#### 1. 核心特点\n",
    "- 解决深层网络训练难题：通过残差结构的跳跃连接，梯度可直接从深层回流到浅层，避免梯度消失/爆炸，使得训练1000层以上的网络成为可能。  \n",
    "- 性能随深度提升：突破了“深度饱和”限制，更深的网络（如ResNet-152）比浅层网络（如ResNet-18）能学习更复杂的特征，精度更高。  \n",
    "\n",
    "\n",
    "#### 2. 典型版本及结构差异\n",
    "ResNet有多个经典版本（ResNet-18/34/50/101/152），命名中的数字代表“网络总层数”（含卷积层和全连接层），核心差异在于**残差块的类型和数量**：  \n",
    "\n",
    "| 版本       | 残差块类型 | 残差块数量（按组划分） | 总层数 |\n",
    "|------------|------------|------------------------|--------|\n",
    "| ResNet-18  | 基本块     | 2+2+2+2                | 18     |\n",
    "| ResNet-34  | 基本块     | 3+4+6+3                | 34     |\n",
    "| ResNet-50  | 瓶颈块     | 3+4+6+3                | 50     |\n",
    "| ResNet-101 | 瓶颈块     | 3+4+23+3               | 101    |\n",
    "| ResNet-152 | 瓶颈块     | 3+8+36+3               | 152    |\n",
    "\n",
    "\n",
    "#### 3. 通用结构框架\n",
    "所有ResNet的整体流程一致，可分为5个部分：  \n",
    "1. **初始卷积层**：7x7大卷积（步长2）+ 3x3最大池化（步长2），快速缩小特征图尺寸（如输入224x224→56x56），并提取低级特征。  \n",
    "2. **残差块组**：4组堆叠的残差块（对应上表中的“按组划分”），每组内通过残差块逐步提升特征图的通道数（如64→128→256→512），并通过步长=2的卷积实现2次降采样（最终特征图尺寸从56x56→28x28→14x14→7x7）。  \n",
    "3. **全局平均池化**：将最后一个残差块的输出（如7x7x512）通过全局平均池化压缩为1x1x512的向量。  \n",
    "4. **全连接层**：将向量映射到任务类别（如ImageNet的1000类），输出分类概率。  \n",
    "\n",
    "\n",
    "#### 4. 经典ResNet-50示例\n",
    "以应用最广泛的ResNet-50为例，具体结构如下：  \n",
    "- 初始层：7x7卷积（64通道，步长2）→ BN → ReLU → 3x3池化（步长2）→ 输出尺寸56x56x64。  \n",
    "- 残差块组1（3个瓶颈块）：保持尺寸56x56，通道数从64→256（通过投影捷径调整初始$x$的维度）。  \n",
    "- 残差块组2（4个瓶颈块）：步长=2降采样至28x28，通道数256→512。  \n",
    "- 残差块组3（6个瓶颈块）：步长=2降采样至14x14，通道数512→1024。  \n",
    "- 残差块组4（3个瓶颈块）：步长=2降采样至7x7，通道数1024→2048。  \n",
    "- 最终层：全局平均池化（7x7→1x1）→ 全连接层（1000类）。  \n",
    "\n",
    "\n",
    "### 三、总结\n",
    "- **残差结构**是ResNet的核心，通过“学习残差+跳跃连接”解决了深层网络的优化难题，使得梯度可高效反向传播。  \n",
    "- **ResNet**通过堆叠残差块实现了超深层网络的训练，突破了传统CNN的深度限制，极大推动了计算机视觉（如分类、检测、分割）的发展。后续许多网络（如ResNeXt、DenseNet）均借鉴了残差连接的思想。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d454d01-f4cb-4f4b-9a8a-8af1bf2005ab",
   "metadata": {},
   "source": [
    "# 残差块儿无池化层 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9aa429-3324-480e-a985-de0aabb6df83",
   "metadata": {},
   "source": [
    "是的，ResNet中的残差块（无论是基本块还是瓶颈块）**本身不包含池化层**。残差块的核心是通过卷积层学习残差函数，然后通过跳跃连接将输入与输出相加。不过，ResNet网络中确实存在下采样操作，但这些操作是通过**带步长的卷积层**而非传统的池化层实现的。以下是详细说明：\n",
    "\n",
    "\n",
    "## 一、残差块内部无池化层\n",
    "残差块的设计目标是学习输入与输出之间的残差映射，其结构主要由**卷积层、批量归一化（BN）和ReLU激活函数**组成。以两种典型残差块为例：\n",
    "1. **基本块（Basic Block）**：  \n",
    "   由两个3x3卷积层（每个卷积层后接BN和ReLU）组成，没有池化层。  \n",
    "   流程：`x → Conv3x3 → BN → ReLU → Conv3x3 → BN → [+x] → ReLU`\n",
    "\n",
    "2. **瓶颈块（Bottleneck Block）**：  \n",
    "   由1x1（降维）、3x3、1x1（升维）三个卷积层组成，同样不含池化层。  \n",
    "   流程：`x → Conv1x1 → BN → ReLU → Conv3x3 → BN → ReLU → Conv1x1 → BN → [+x] → ReLU`\n",
    "\n",
    "\n",
    "## 二、ResNet中的下采样如何实现？\n",
    "虽然残差块内部没有池化层，但ResNet网络在某些位置需要进行**下采样**（如特征图尺寸从56x56→28x28）。ResNet通过以下方式实现下采样：\n",
    "1. **带步长的卷积层**：  \n",
    "   在残差块的第一个卷积层（通常是3x3卷积或1x1卷积）中设置**步长=2**，从而实现特征图尺寸减半。例如，ResNet-50的瓶颈块组2-4的第一个1x1卷积使用步长=2进行下采样。\n",
    "\n",
    "2. **投影捷径（Projection Shortcut）**：  \n",
    "   当下采样导致输入$x$与主路径输出维度不一致时，跳跃连接需要通过1x1卷积对$x$进行投影，使其维度与主路径匹配。此时，1x1卷积也会使用步长=2，确保$x$的空间尺寸与主路径输出一致。\n",
    "\n",
    "\n",
    "## 三、ResNet中的池化层位置\n",
    "ResNet中**仅在网络前端和后端存在池化层**，而非残差块内部：\n",
    "1. **初始层的最大池化**：  \n",
    "   在第一个卷积层（7x7卷积）之后，使用3x3最大池化（步长=2）对输入图像进行下采样，这是网络的第一个下采样操作。\n",
    "\n",
    "2. **全局平均池化（GAP）**：  \n",
    "   在所有残差块组之后，使用全局平均池化将特征图压缩为1x1向量，用于后续的全连接层分类。\n",
    "\n",
    "\n",
    "## 四、为什么不使用池化层？\n",
    "1. **保留更多信息**：  \n",
    "   池化层（尤其是最大池化）会丢失部分空间信息，而带步长的卷积层可以在降采样的同时保留更多特征信息。\n",
    "\n",
    "2. **梯度流动更顺畅**：  \n",
    "   残差块的设计依赖于跳跃连接传递梯度，避免使用池化层可以减少梯度路径中的非线性操作，进一步缓解梯度消失问题。\n",
    "\n",
    "\n",
    "## 五、总结\n",
    "- **残差块内部**确实没有池化层，其结构以卷积层为主。  \n",
    "- **ResNet网络中的下采样**通过带步长的卷积层实现，而非传统池化层。  \n",
    "- **池化层仅存在于网络的初始阶段（最大池化）和末尾（全局平均池化）**。\n",
    "\n",
    "这种设计使ResNet能够在保持特征表达能力的同时，高效地进行深层网络训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13f5ff5-ef3a-4d28-a9ba-7219a672e354",
   "metadata": {},
   "source": [
    "## 代码实现  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06f7354f-9d1a-4253-9312-5d2e25864e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b56d745-03e0-4d46-bde2-6d307910a557",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetbasicBlock(nn.Module): \n",
    "    def __init__(self,in_channels,out_channels): \n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels\n",
    "                              ,out_channels, \n",
    "                               kernel_size=3, #用3*3的卷积核\n",
    "                               padding=1, \n",
    "                               bias=False\n",
    "                              )\n",
    "        #设置bn层\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels\n",
    "                              ,out_channels, \n",
    "                               kernel_size=3, #用3*3的卷积核\n",
    "                               padding=1, \n",
    "                               bias=False\n",
    "                              )\n",
    "        #设置bn层\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "    def forward(self,x): #x写为input也可\n",
    "        residual = x\n",
    "        x = F.relu(self.bn1(self.conv1(x)),inplace=True) #inplace = True为就地改变\n",
    "        x = F.relu(self.bn2(self.conv2v(x)),inplace=True) \n",
    "\n",
    "        #关键的一步,实现F(x)+x \n",
    "        x+=residual \n",
    "        return F.relu(x)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c28525aa-4d28-40b3-9144-64c5ee629992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "model = torchvision.models.resnet18(weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d14e2383-0cab-4e7f-aa68-8cd700fc5c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cb4315f-6642-42e1-8da0-5f79bc777e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mweights\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResNet18_Weights\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mprogress\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "\u001b[1;33m@\u001b[0m\u001b[0mregister_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mhandle_legacy_interface\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pretrained\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mResNet18_Weights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMAGENET1K_V1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;32mdef\u001b[0m \u001b[0mresnet18\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mResNet18_Weights\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mResNet\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;34m\"\"\"ResNet-18 from `Deep Residual Learning for Image Recognition <https://arxiv.org/abs/1512.03385>`__.\n",
       "\n",
       "    Args:\n",
       "        weights (:class:`~torchvision.models.ResNet18_Weights`, optional): The\n",
       "            pretrained weights to use. See\n",
       "            :class:`~torchvision.models.ResNet18_Weights` below for\n",
       "            more details, and possible values. By default, no pre-trained\n",
       "            weights are used.\n",
       "        progress (bool, optional): If True, displays a progress bar of the\n",
       "            download to stderr. Default is True.\n",
       "        **kwargs: parameters passed to the ``torchvision.models.resnet.ResNet``\n",
       "            base class. Please refer to the `source code\n",
       "            <https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py>`_\n",
       "            for more details about this class.\n",
       "\n",
       "    .. autoclass:: torchvision.models.ResNet18_Weights\n",
       "        :members:\n",
       "    \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResNet18_Weights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0m_resnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBasicBlock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      d:\\venvs\\dl\\lib\\site-packages\\torchvision\\models\\resnet.py\n",
       "\u001b[1;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = torchvision.models.resnet18??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bc9811-ebdd-4a64-9550-d657b5a5987a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
