{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d5e40b-c407-42f1-b803-d2a015f6dca8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tensorrt_bindings.tensorrt.IBuilderConfig' object has no attribute 'max_workspace_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m engine_path\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# è½¬æ¢æ¨¡å‹ï¼ˆæ›¿æ¢ä¸ºä½ çš„ ONNX è·¯å¾„ï¼‰\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[43mbuild_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpet_detection_model.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpet_detection.engine\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m, in \u001b[0;36mbuild_engine\u001b[1;34m(onnx_path, engine_path)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# é…ç½®æ„å»ºå‚æ•°\u001b[39;00m\n\u001b[0;32m     15\u001b[0m config \u001b[38;5;241m=\u001b[39m builder\u001b[38;5;241m.\u001b[39mcreate_builder_config()\n\u001b[1;32m---> 16\u001b[0m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_workspace_size\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<<\u001b[39m \u001b[38;5;241m30\u001b[39m  \u001b[38;5;66;03m# 1GB å·¥ä½œç©ºé—´\u001b[39;00m\n\u001b[0;32m     17\u001b[0m config\u001b[38;5;241m.\u001b[39mset_flag(trt\u001b[38;5;241m.\u001b[39mBuilderFlag\u001b[38;5;241m.\u001b[39mFP16)  \u001b[38;5;66;03m# å¯ç”¨ FP16 åŠ é€Ÿï¼ˆéœ€ GPU æ”¯æŒï¼‰\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# æ„å»ºå¹¶ä¿å­˜å¼•æ“\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tensorrt_bindings.tensorrt.IBuilderConfig' object has no attribute 'max_workspace_size'"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "def build_engine(onnx_path, engine_path):\n",
    "    with trt.Builder(TRT_LOGGER) as builder, \\\n",
    "         builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)) as network, \\\n",
    "         trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "        \n",
    "        # è§£æ ONNX æ¨¡å‹\n",
    "        with open(onnx_path, 'rb') as f:\n",
    "            parser.parse(f.read())\n",
    "        \n",
    "        # é…ç½®æ„å»ºå‚æ•°\n",
    "        config = builder.create_builder_config()\n",
    "        config.max_workspace_size = 1 << 30  # 1GB å·¥ä½œç©ºé—´\n",
    "        config.set_flag(trt.BuilderFlag.FP16)  # å¯ç”¨ FP16 åŠ é€Ÿï¼ˆéœ€ GPU æ”¯æŒï¼‰\n",
    "        \n",
    "        # æ„å»ºå¹¶ä¿å­˜å¼•æ“\n",
    "        engine = builder.build_engine(network, config)\n",
    "        with open(engine_path, 'wb') as f:\n",
    "            f.write(engine.serialize())\n",
    "    return engine_path\n",
    "\n",
    "# è½¬æ¢æ¨¡å‹ï¼ˆæ›¿æ¢ä¸ºä½ çš„ ONNX è·¯å¾„ï¼‰\n",
    "build_engine(\"pet_detection_model.onnx\", \"pet_detection.engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7013a256-c76a-4dce-9905-e5459bd96545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼•æ“æ„å»ºå¤±è´¥ï¼\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "def build_engine(onnx_path, engine_path):\n",
    "    with trt.Builder(TRT_LOGGER) as builder, \\\n",
    "         builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)) as network, \\\n",
    "         trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "        \n",
    "        # è§£æ ONNX æ¨¡å‹\n",
    "        with open(onnx_path, 'rb') as f:\n",
    "            if not parser.parse(f.read()):\n",
    "                print(\"ONNX è§£æå¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯ï¼š\")\n",
    "                for error in range(parser.num_errors):\n",
    "                    print(parser.get_error(error))\n",
    "                return None\n",
    "        \n",
    "        # é…ç½®æ„å»ºå‚æ•°\n",
    "        config = builder.create_builder_config()\n",
    "        config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)  # 1GB\n",
    "        \n",
    "        # å¯ç”¨ FP16 åŠ é€Ÿï¼ˆéœ€ GPU æ”¯æŒï¼‰\n",
    "        if builder.platform_has_fast_fp16:\n",
    "            config.set_flag(trt.BuilderFlag.FP16)\n",
    "        \n",
    "        # æ„å»ºå¹¶ä¿å­˜å¼•æ“ï¼ˆé€‚é…æ–°ç‰ˆæœ¬ APIï¼‰\n",
    "        serialized_engine = builder.build_serialized_network(network, config)\n",
    "        if serialized_engine is None:\n",
    "            print(\"å¼•æ“æ„å»ºå¤±è´¥ï¼\")\n",
    "            return None\n",
    "            \n",
    "        with open(engine_path, 'wb') as f:\n",
    "            f.write(serialized_engine)\n",
    "        return engine_path\n",
    "\n",
    "# è½¬æ¢æ¨¡å‹\n",
    "build_engine(\"pet_detection_model.onnx\", \"pet_detection.engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67769c95-ff09-4bfb-a0b6-be1af0b53729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ æ­£åœ¨è§£æ ONNX æ¨¡å‹: pet_detection_model.onnx\n",
      "âœ… ONNX è§£ææˆåŠŸï¼Œç½‘ç»œå±‚æ•°: 274\n",
      "ğŸ”„ å¯ç”¨ FP16 ç²¾åº¦\n",
      "ğŸ”„ æ­£åœ¨æ„å»º TensorRT å¼•æ“...\n",
      "âŒ å¼•æ“æ„å»ºå¤±è´¥ï¼\n",
      "  - æˆåŠŸè§£æç½‘ç»œï¼Œå±‚æ•°: 274\n",
      "  - æœ€åä¸€å±‚: /Squeeze_3, ç±»å‹: LayerType.SQUEEZE\n",
      "  - æ‰€æœ‰è¾“å‡ºå‡å·²è¿æ¥\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "import os\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.ERROR)  # ä½¿ç”¨ ERROR çº§åˆ«å‡å°‘å†—ä½™æ—¥å¿—\n",
    "\n",
    "def build_engine(onnx_path, engine_path, fp16=True, workspace_size=2):\n",
    "    \"\"\"æ„å»º TensorRT å¼•æ“\n",
    "    \n",
    "    Args:\n",
    "        onnx_path: ONNX æ¨¡å‹è·¯å¾„\n",
    "        engine_path: ä¿å­˜å¼•æ“çš„è·¯å¾„\n",
    "        fp16: æ˜¯å¦å¯ç”¨ FP16 ç²¾åº¦\n",
    "        workspace_size: å·¥ä½œç©ºé—´å¤§å°ï¼ˆGBï¼‰\n",
    "    \"\"\"\n",
    "    # å¦‚æœå¼•æ“å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›\n",
    "    if os.path.exists(engine_path):\n",
    "        print(f\"âœ… å¼•æ“å·²å­˜åœ¨: {engine_path}\")\n",
    "        return engine_path\n",
    "        \n",
    "    # åˆ›å»ºæ„å»ºå™¨å’Œç½‘ç»œ\n",
    "    builder = trt.Builder(TRT_LOGGER)\n",
    "    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "    parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "    \n",
    "    # è§£æ ONNX æ¨¡å‹\n",
    "    print(f\"ğŸ”„ æ­£åœ¨è§£æ ONNX æ¨¡å‹: {onnx_path}\")\n",
    "    with open(onnx_path, 'rb') as f:\n",
    "        if not parser.parse(f.read()):\n",
    "            print(\"âŒ ONNX è§£æå¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯:\")\n",
    "            for error in range(parser.num_errors):\n",
    "                print(f\"  - {parser.get_error(error)}\")\n",
    "            return None\n",
    "            \n",
    "    print(f\"âœ… ONNX è§£ææˆåŠŸï¼Œç½‘ç»œå±‚æ•°: {network.num_layers}\")\n",
    "    \n",
    "    # é…ç½®æ„å»ºå‚æ•°\n",
    "    config = builder.create_builder_config()\n",
    "    config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, workspace_size << 30)\n",
    "    \n",
    "    # å¯ç”¨ FP16ï¼ˆå¦‚æœæ”¯æŒï¼‰\n",
    "    if fp16 and builder.platform_has_fast_fp16:\n",
    "        print(\"ğŸ”„ å¯ç”¨ FP16 ç²¾åº¦\")\n",
    "        config.set_flag(trt.BuilderFlag.FP16)\n",
    "    else:\n",
    "        print(\"ğŸ”„ ä½¿ç”¨ FP32 ç²¾åº¦\")\n",
    "    \n",
    "    # æ„å»ºå¹¶ä¿å­˜å¼•æ“\n",
    "    print(\"ğŸ”„ æ­£åœ¨æ„å»º TensorRT å¼•æ“...\")\n",
    "    serialized_engine = builder.build_serialized_network(network, config)\n",
    "    \n",
    "    if serialized_engine is None:\n",
    "        print(\"âŒ å¼•æ“æ„å»ºå¤±è´¥ï¼\")\n",
    "        \n",
    "        # è¾“å‡ºè¯¦ç»†é”™è¯¯ä¿¡æ¯\n",
    "        if network.num_layers == 0:\n",
    "            print(\"  - ç½‘ç»œå±‚æ•°ä¸º0ï¼ŒONNXè§£æå¯èƒ½å¤±è´¥\")\n",
    "        else:\n",
    "            print(f\"  - æˆåŠŸè§£æç½‘ç»œï¼Œå±‚æ•°: {network.num_layers}\")\n",
    "            \n",
    "        # æ£€æŸ¥æœ€åä¸€å±‚\n",
    "        last_layer = network.get_layer(network.num_layers - 1)\n",
    "        print(f\"  - æœ€åä¸€å±‚: {last_layer.name}, ç±»å‹: {last_layer.type}\")\n",
    "        \n",
    "        # æ£€æŸ¥æœªè¿æ¥çš„è¾“å‡º\n",
    "        unconnected_outputs = False\n",
    "        for i in range(network.num_layers):\n",
    "            layer = network.get_layer(i)\n",
    "            for j in range(layer.num_outputs):\n",
    "                if not layer.get_output(j):\n",
    "                    print(f\"  - âŒ ç¬¬ {i} å±‚çš„ç¬¬ {j} ä¸ªè¾“å‡ºæœªè¿æ¥\")\n",
    "                    unconnected_outputs = True\n",
    "                    \n",
    "        if not unconnected_outputs:\n",
    "            print(\"  - æ‰€æœ‰è¾“å‡ºå‡å·²è¿æ¥\")\n",
    "            \n",
    "        return None\n",
    "        \n",
    "    # ä¿å­˜å¼•æ“\n",
    "    with open(engine_path, 'wb') as f:\n",
    "        f.write(serialized_engine)\n",
    "        \n",
    "    print(f\"âœ… å¼•æ“å·²æˆåŠŸä¿å­˜åˆ°: {engine_path}\")\n",
    "    return engine_path\n",
    "\n",
    "# è½¬æ¢æ¨¡å‹\n",
    "build_engine(\n",
    "    onnx_path=\"pet_detection_model.onnx\",\n",
    "    engine_path=\"pet_detection.engine\",\n",
    "    fp16=True,\n",
    "    workspace_size=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48eae08c-de69-4fd5-9fab-a461da8fbe7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ æ­£åœ¨ä¿®å¤ ONNX æ¨¡å‹ä¸­çš„ Squeeze èŠ‚ç‚¹: pet_detection_model.onnx\n",
      "  - æ‰¾åˆ° Squeeze èŠ‚ç‚¹: /Squeeze\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 141\u001b[0m\n\u001b[0;32m    138\u001b[0m original_onnx_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpet_detection_model.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# ä¿®å¤ ONNX æ¨¡å‹\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m fixed_onnx_path \u001b[38;5;241m=\u001b[39m \u001b[43mfix_onnx_squeeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_onnx_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_onnx_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# æ„å»ºå¼•æ“\u001b[39;00m\n\u001b[0;32m    144\u001b[0m build_engine(\n\u001b[0;32m    145\u001b[0m     onnx_path\u001b[38;5;241m=\u001b[39mfixed_onnx_path,\n\u001b[0;32m    146\u001b[0m     engine_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpet_detection.engine\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    147\u001b[0m     fp16\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    148\u001b[0m     workspace_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    149\u001b[0m )\n",
      "Cell \u001b[1;32mIn[7], line 29\u001b[0m, in \u001b[0;36mfix_onnx_squeeze\u001b[1;34m(onnx_path, output_path)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# è®¡ç®—æ–°å½¢çŠ¶ï¼ˆç§»é™¤ç»´åº¦ä¸º1çš„è½´ï¼‰\u001b[39;00m\n\u001b[0;32m     28\u001b[0m new_shape \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, dim \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_tensor\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (i \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39mattrs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m\"\u001b[39m, []) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39mattrs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     31\u001b[0m         new_shape\u001b[38;5;241m.\u001b[39mappend(dim)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "import os\n",
    "import onnx\n",
    "import onnx_graphsurgeon as gs\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.ERROR)\n",
    "\n",
    "def fix_onnx_squeeze(onnx_path, output_path):\n",
    "    \"\"\"ä¿®å¤ ONNX æ¨¡å‹ä¸­çš„ Squeeze èŠ‚ç‚¹\"\"\"\n",
    "    print(f\"ğŸ”„ æ­£åœ¨ä¿®å¤ ONNX æ¨¡å‹ä¸­çš„ Squeeze èŠ‚ç‚¹: {onnx_path}\")\n",
    "    \n",
    "    # åŠ è½½ ONNX æ¨¡å‹\n",
    "    graph = gs.import_onnx(onnx.load(onnx_path))\n",
    "    \n",
    "    # æŸ¥æ‰¾å¹¶æ›¿æ¢ Squeeze èŠ‚ç‚¹\n",
    "    squeeze_count = 0\n",
    "    for node in graph.nodes:\n",
    "        if node.op == \"Squeeze\":\n",
    "            # è®°å½• Squeeze èŠ‚ç‚¹\n",
    "            squeeze_count += 1\n",
    "            print(f\"  - æ‰¾åˆ° Squeeze èŠ‚ç‚¹: {node.name}\")\n",
    "            \n",
    "            # åˆ›å»ºæ–°çš„ Reshape èŠ‚ç‚¹æ›¿ä»£ Squeeze\n",
    "            input_tensor = node.inputs[0]\n",
    "            output_tensor = node.outputs[0]\n",
    "            \n",
    "            # è®¡ç®—æ–°å½¢çŠ¶ï¼ˆç§»é™¤ç»´åº¦ä¸º1çš„è½´ï¼‰\n",
    "            new_shape = []\n",
    "            for i, dim in enumerate(input_tensor.shape):\n",
    "                if dim != 1 or (i in node.attrs.get(\"axes\", []) if \"axes\" in node.attrs else True):\n",
    "                    new_shape.append(dim)\n",
    "            \n",
    "            # åˆ›å»ºå½¢çŠ¶å¼ é‡\n",
    "            shape_tensor = gs.Constant(name=f\"{node.name}_shape\", values=np.array(new_shape, dtype=np.int64))\n",
    "            \n",
    "            # åˆ›å»º Reshape èŠ‚ç‚¹\n",
    "            reshape_node = gs.Node(\n",
    "                op=\"Reshape\",\n",
    "                name=f\"{node.name}_reshape\",\n",
    "                inputs=[input_tensor, shape_tensor],\n",
    "                outputs=[output_tensor]\n",
    "            )\n",
    "            \n",
    "            # æ·»åŠ æ–°èŠ‚ç‚¹å¹¶ç§»é™¤åŸ Squeeze èŠ‚ç‚¹\n",
    "            graph.nodes.append(reshape_node)\n",
    "            node.outputs = []\n",
    "    \n",
    "    if squeeze_count > 0:\n",
    "        print(f\"âœ… æˆåŠŸæ›¿æ¢ {squeeze_count} ä¸ª Squeeze èŠ‚ç‚¹\")\n",
    "        # æ¸…ç†å¹¶ä¿å­˜ä¿®æ”¹åçš„æ¨¡å‹\n",
    "        graph.cleanup().toposort()\n",
    "        onnx.save(gs.export_onnx(graph), output_path)\n",
    "        return output_path\n",
    "    else:\n",
    "        print(\"âœ… æœªå‘ç°éœ€è¦ä¿®å¤çš„ Squeeze èŠ‚ç‚¹\")\n",
    "        return onnx_path\n",
    "\n",
    "def build_engine(onnx_path, engine_path, fp16=True, workspace_size=2):\n",
    "    \"\"\"æ„å»º TensorRT å¼•æ“\"\"\"\n",
    "    # å¦‚æœå¼•æ“å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›\n",
    "    if os.path.exists(engine_path):\n",
    "        print(f\"âœ… å¼•æ“å·²å­˜åœ¨: {engine_path}\")\n",
    "        return engine_path\n",
    "        \n",
    "    # åˆ›å»ºæ„å»ºå™¨å’Œç½‘ç»œ\n",
    "    builder = trt.Builder(TRT_LOGGER)\n",
    "    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "    parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "    \n",
    "    # è§£æ ONNX æ¨¡å‹\n",
    "    print(f\"ğŸ”„ æ­£åœ¨è§£æ ONNX æ¨¡å‹: {onnx_path}\")\n",
    "    with open(onnx_path, 'rb') as f:\n",
    "        if not parser.parse(f.read()):\n",
    "            print(\"âŒ ONNX è§£æå¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯:\")\n",
    "            for error in range(parser.num_errors):\n",
    "                print(f\"  - {parser.get_error(error)}\")\n",
    "            return None\n",
    "            \n",
    "    print(f\"âœ… ONNX è§£ææˆåŠŸï¼Œç½‘ç»œå±‚æ•°: {network.num_layers}\")\n",
    "    \n",
    "    # é…ç½®æ„å»ºå‚æ•°\n",
    "    config = builder.create_builder_config()\n",
    "    config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, workspace_size << 30)\n",
    "    \n",
    "    # å¯ç”¨ FP16ï¼ˆå¦‚æœæ”¯æŒï¼‰\n",
    "    if fp16 and builder.platform_has_fast_fp16:\n",
    "        print(\"ğŸ”„ å¯ç”¨ FP16 ç²¾åº¦\")\n",
    "        config.set_flag(trt.BuilderFlag.FP16)\n",
    "        \n",
    "        # å¯¹æ‰€æœ‰ Squeeze å±‚å¼ºåˆ¶ä½¿ç”¨ FP32\n",
    "        for i in range(network.num_layers):\n",
    "            layer = network.get_layer(i)\n",
    "            if layer.type == trt.LayerType.SQUEEZE:\n",
    "                print(f\"  - å¯¹ Squeeze å±‚ {layer.name} ä½¿ç”¨ FP32 ç²¾åº¦\")\n",
    "                layer.precision = trt.DataType.FLOAT\n",
    "                layer.set_output_type(0, trt.DataType.FLOAT)\n",
    "    \n",
    "    # æ„å»ºå¹¶ä¿å­˜å¼•æ“\n",
    "    print(\"ğŸ”„ æ­£åœ¨æ„å»º TensorRT å¼•æ“...\")\n",
    "    serialized_engine = builder.build_serialized_network(network, config)\n",
    "    \n",
    "    if serialized_engine is None:\n",
    "        print(\"âŒ å¼•æ“æ„å»ºå¤±è´¥ï¼\")\n",
    "        \n",
    "        # è¾“å‡ºè¯¦ç»†é”™è¯¯ä¿¡æ¯\n",
    "        if network.num_layers == 0:\n",
    "            print(\"  - ç½‘ç»œå±‚æ•°ä¸º0ï¼ŒONNXè§£æå¯èƒ½å¤±è´¥\")\n",
    "        else:\n",
    "            print(f\"  - æˆåŠŸè§£æç½‘ç»œï¼Œå±‚æ•°: {network.num_layers}\")\n",
    "            \n",
    "        # æ£€æŸ¥æœ€åä¸€å±‚\n",
    "        last_layer = network.get_layer(network.num_layers - 1)\n",
    "        print(f\"  - æœ€åä¸€å±‚: {last_layer.name}, ç±»å‹: {last_layer.type}\")\n",
    "        \n",
    "        # æ£€æŸ¥æœªè¿æ¥çš„è¾“å‡º\n",
    "        unconnected_outputs = False\n",
    "        for i in range(network.num_layers):\n",
    "            layer = network.get_layer(i)\n",
    "            for j in range(layer.num_outputs):\n",
    "                if not layer.get_output(j):\n",
    "                    print(f\"  - âŒ ç¬¬ {i} å±‚çš„ç¬¬ {j} ä¸ªè¾“å‡ºæœªè¿æ¥\")\n",
    "                    unconnected_outputs = True\n",
    "                    \n",
    "        if not unconnected_outputs:\n",
    "            print(\"  - æ‰€æœ‰è¾“å‡ºå‡å·²è¿æ¥\")\n",
    "            \n",
    "        return None\n",
    "        \n",
    "    # ä¿å­˜å¼•æ“\n",
    "    with open(engine_path, 'wb') as f:\n",
    "        f.write(serialized_engine)\n",
    "        \n",
    "    print(f\"âœ… å¼•æ“å·²æˆåŠŸä¿å­˜åˆ°: {engine_path}\")\n",
    "    return engine_path\n",
    "\n",
    "# ä¸»æµç¨‹\n",
    "fixed_onnx_path = \"pet_detection_model_fixed.onnx\"\n",
    "original_onnx_path = \"pet_detection_model.onnx\"\n",
    "\n",
    "# ä¿®å¤ ONNX æ¨¡å‹\n",
    "fixed_onnx_path = fix_onnx_squeeze(original_onnx_path, fixed_onnx_path)\n",
    "\n",
    "# æ„å»ºå¼•æ“\n",
    "build_engine(\n",
    "    onnx_path=fixed_onnx_path,\n",
    "    engine_path=\"pet_detection.engine\",\n",
    "    fp16=True,\n",
    "    workspace_size=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977df068-53a3-4e04-8fed-b57dc0dbbef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
